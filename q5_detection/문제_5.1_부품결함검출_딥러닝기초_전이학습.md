## 문제 5.1: 자동차 부품 결함 검출(딥러닝 기초 + 전이학습)

### [ 시험 정보 ]
| 항목 | 내용 |
|------|------|
| 과정 | AI 올인원 |
| 단계 | AI/SW 심화 |
| 난이도 | 3 |
| 권장 시간 | 40분 |
| 관련 과목 | 딥러닝, 컴퓨터 비전, 자연어 처리, 머신러닝, 데이터 분석 |
| Pass 기준 | 정답 체크리스트 10개 중 10개 모두 충족 |

---

### [ 문제 ]

당신은 자동차 부품 제조사의 품질관리 AI 엔지니어입니다.
생산 라인에서 촬영된 **부품 이미지**(`part_images/`)와 **검사 기록**(`inspection_log.csv`)을 활용하여,
부품의 결함 유형을 자동으로 분류하는 시스템을 **3가지 방식**으로 구축하고 비교해야 합니다.

> **⚠ 주의:**
> - 레이블 분포는 **불균형** 상태입니다 (양품이 다수).
> - 이미지 일부에 **손상된 파일**이 포함되어 있을 수 있습니다.
> - CSV의 텍스트 데이터에 **인코딩 불일치** 또는 **누락값**이 있을 수 있습니다.

다음 요구사항을 모두 충족하는 Python 스크립트 `q6_solution.py`를 작성하십시오.

---

### [ 요구사항 ]

#### Part A: 데이터 전처리 (클래스 기반 구현)

1. **`DefectImageLoader` 클래스**를 구현하세요:
   - 이미지를 **RGB 모드**로 변환 (Grayscale/RGBA 등 대응)
   - **64×64**로 리사이즈
   - **[0, 1] 범위**로 정규화 (`/255.0`)
   - 손상된 이미지(열 수 없거나 검증 실패)는 **건너뛰기**
   - 유효한 이미지만 **flatten**하여 반환 (64×64×3 = 12288차원)

2. **`InspectionLogProcessor` 클래스**를 구현하세요:
   - `inspection_log.csv` 로드
   - **중복 `part_id`** 제거 (`keep='first'`)
   - `defect_type`의 **유니코드 정규화(NFC)** 및 **공백 제거**
   - 유효 레이블: `["양품", "스크래치", "크랙", "변색", "이물질"]`에 해당하지 않는 행 제거
   - `inspector_note`의 **결측값(NaN)**을 빈 문자열(`""`)로 대체
   - 이미지가 유효한 `part_id`만 남기기

3. **출력**: 정제 후 유효 샘플 수, 레이블별 분포, 불균형 비율(최대/최소)

#### Part B: 3단계 모델 비교

4. **데이터 분할**: train(70%) / test(30%), `random_state=42`, `stratify=labels`

5. **B-1. 규칙 기반 (엣지 강도)** — Q3 복습:
   - **NumPy**로 `conv2d(image, kernel)` 함수 직접 구현 (valid 모드)
   - Sobel 커널(3×3)로 수평/수직 엣지 검출 → `edge_magnitude = sqrt(Gx² + Gy²)`
   - 각 이미지의 **엣지 평균 강도**를 계산
   - 임계값 기반 분류: 엣지 강도 ≤ `threshold` → 양품(0), 그 외 → 불량(1) (**이진 분류**)
   - `threshold`는 train 데이터 양품 클래스의 엣지 강도 **중앙값**으로 설정

6. **B-2. ML 기반 (특징 추출 + LR)** — Q5 복습:
   - **이미지 특징**: flatten → PCA (`n_components` = 95% 분산 설명)
   - **텍스트 특징**: `inspector_note`에 대해 TF-IDF (`TfidfVectorizer`, `max_features=100`)
   - 이미지 + 텍스트 특징을 **수평 결합** (`np.hstack`)
   - `LogisticRegression(C=1.0, max_iter=1000, random_state=42)` 학습 (**5클래스 분류**)

7. **B-3. 2층 신경망 Forward Pass (NumPy 직접 구현)** — ★새 역량:
   - `pretrained_nn_weights.npz`에서 가중치 로드: `W1`, `b1`, `W2`, `b2`, `feature_mean`, `feature_std`
   - `pretrained_features.npy`에서 특징 벡터 로드
   - **정규화**: `X_norm = (X - feature_mean) / feature_std`
   - **Forward Pass**:
     ```
     z1 = X_norm @ W1 + b1
     a1 = ReLU(z1)           ← max(0, z1)
     z2 = a1 @ W2 + b2
     probs = Softmax(z2)     ← exp(z2) / sum(exp(z2))  (수치 안정성 주의)
     pred = argmax(probs)
     ```
   - ⚠ Softmax 구현 시 **오버플로 방지**: 각 행에서 최댓값을 빼고 `exp` 적용

#### Part C: 전이학습 비교

8. **Scratch vs Pretrained 비교**:
   - **Scratch 모델**: Part B-2의 PCA 이미지 특징(**텍스트 제외**) → `LogisticRegression` 학습
   - **Pretrained 모델**: `pretrained_features.npy`의 특징 → 같은 설정의 `LogisticRegression` 학습
   - 두 모델의 **test Accuracy 차이**를 `transfer_gain`으로 산출
   - ⚠ `pretrained_features.npy`의 인덱스는 원본 `part_id` 순서(0000~0499)에 대응

#### Part D: 성능 평가 + 개선 + 비즈니스 보고서

9. **성능 평가**:
   - 모든 모델의 **test Accuracy**
   - ML(B-2), Pretrained(C) 모델의 **Macro F1-score**
   - Pretrained 모델의 **클래스별 F1-score** (5개)
   - Pretrained 모델의 **Confusion Matrix** (5×5, 리스트의 리스트)

10. **개선 실험**:
    - Pretrained 모델에 `class_weight='balanced'` 적용 전/후 **Macro F1** 비교
    - 어떤 클래스의 F1이 가장 많이 **개선**되었는지 보고

11. **비즈니스 보고서** (4개 섹션, 각 3문장 이내):
    - `purpose`: 이 시스템의 목적과 기대 효과
    - `key_results`: 핵심 수치 결과 (정확도, F1 등)
    - `transfer_learning_effect`: 전이학습의 효과와 의미
    - `improvement_suggestion`: 향후 개선 방향 제안

---

### [ 제약 사항 ]
- `conv2d` 함수는 **NumPy만으로 직접 구현** (`cv2.filter2D` 등 사용 금지)
- 2층 신경망 Forward Pass는 **NumPy만으로 직접 구현** (PyTorch/Keras 금지)
- 이미지 로드에는 `PIL` 사용 가능
- `PCA`, `TfidfVectorizer`, `LogisticRegression`은 `sklearn` 사용 허용
- 모든 수치는 **소수점 이하 4자리**로 반올림

---

### [ 입력 형식 ]

| 파일/폴더 | 설명 |
|-----------|------|
| `part_images/` | `0000.png` ~ `0499.png` (64×64, 일부 손상 포함) |
| `inspection_log.csv` | `part_id`, `defect_type`, `inspector_note` |
| `pretrained_features.npy` | 사전학습 특징 벡터 (500×128) |
| `pretrained_nn_weights.npz` | 2층 NN 가중치 (`W1`, `b1`, `W2`, `b2`, `feature_mean`, `feature_std`) |

---

### [ 출력 형식 ]

`result_q6.json` 파일로 다음 구조를 저장하세요:

```json
{
  "data_summary": {
    "total_valid_samples": 정수,
    "label_distribution": {"양품": 정수, "스크래치": 정수, "크랙": 정수, "변색": 정수, "이물질": 정수},
    "imbalance_ratio": 실수
  },
  "rule_based": {
    "test_accuracy": 실수,
    "method": "edge_threshold_binary"
  },
  "ml_based": {
    "test_accuracy": 실수,
    "test_f1_macro": 실수,
    "pca_n_components": 정수
  },
  "nn_forward": {
    "test_accuracy": 실수,
    "test_f1_macro": 실수
  },
  "pretrained": {
    "test_accuracy": 실수,
    "test_f1_macro": 실수,
    "class_f1": {"양품": 실수, "스크래치": 실수, "크랙": 실수, "변색": 실수, "이물질": 실수},
    "confusion_matrix": [[정수 5개], ...]
  },
  "transfer_gain": 실수,
  "improvement": {
    "before_f1": 실수,
    "after_f1": 실수,
    "most_improved_class": "문자열"
  },
  "report": {
    "purpose": "3문장 이내",
    "key_results": "3문장 이내",
    "transfer_learning_effect": "3문장 이내",
    "improvement_suggestion": "3문장 이내"
  }
}
```

---

### [ 제출 방식 ]

아래 **두 파일**을 `submissions/` 폴더에 제출하세요.

| 파일 | 파일명 형식 | 예시 |
|------|------------|------|
| 솔루션 코드 | `solution_{단계}_q5_{학번}.py` | `solution_advanced_q5_20210001.py` |
| 결과 JSON | `result_{단계}_q5_{학번}.json` | `result_advanced_q5_20210001.json` |

- **단계**: `advanced` (심화) / `basic` (기초) / `intro` (입학연수)
- **학번**: 본인 학번
- 두 파일 모두 제출해야 채점이 진행됩니다.
